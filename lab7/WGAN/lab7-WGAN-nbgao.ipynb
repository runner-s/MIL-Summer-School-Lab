{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验7 WGAN\n",
    "\n",
    "Author: 高鹏昺\n",
    "\n",
    "Email: nbgao@126.com\n",
    "\n",
    "Reference: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html?highlight=gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "workers = 2\n",
    "batch_size = 128\n",
    "image_size = 64\n",
    "nc = 3\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "num_epochs = 8\n",
    "lr = 0.00005\n",
    "beta1 = 0.5\n",
    "clip = 0.01\n",
    "ngpu = 1\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu>0) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ../data/cifar-10-python/\n",
      "    Split: Train\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(root='../data/cifar-10-python/', transform=transform, download=False)\n",
    "print(dataset)\n",
    "dataloader = data.DataLoader(dataset, batch_size, shuffle=True,  num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "            # [nfg*8, 4, 4]\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            # [ngf*4, 8, 8]\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            # [ngf*2, 16, 16]\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            # [ngf, 32, 32]\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # [nc, 64, 64]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.generator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (generator): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (12): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "if (device.type=='cuda' and ngpu>1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "netG.apply(weights_init)\n",
    "\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.discriminator = nn.Sequential(\n",
    "            # [nc, 64, 64]\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [ndf, 32, 32]\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [ndf*2, 16, 16]\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [ndf*4, 8, 8]\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # [ndf*8 ,4, 4]\n",
    "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=True),\n",
    "            # [WGAN] Modification 1: remove sigmoid\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (discriminator): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "if device.type=='cuda' and ngpu>1:\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "netD.apply(weights_init)\n",
    "\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [WGAN] Modification 2: remove log\n",
    "#criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# [WGAN] Modification 3: Use RMSProp optimizzer\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=lr)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/8][0/391]\tLoss_D: -0.0130\tLoss_G: 0.0436\tD(x): -0.0067\tD(G(z)): -0.0063 / 0.0436\n",
      "[0/8][50/391]\tLoss_D: -0.0301\tLoss_G: 0.4533\tD(x): -0.4651\tD(G(z)): 0.4350 / 0.4533\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "time_start = time.time()\n",
    "print('Starting Training Loop...')\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = -1 * one\n",
    "one = one.cuda()\n",
    "mone = mone.cuda()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1-D(G(z)))\n",
    "        \n",
    "        # [WGAN] Modification 4: Clip parameters for Discriminator\n",
    "        for parm in netD.parameters():\n",
    "            parm.data.clamp_(-clip, clip)\n",
    "        \n",
    "        real, _ = data\n",
    "        real = Variable(real).cuda()\n",
    "        noise = torch.randn(real.size(0), nz, 1, 1)\n",
    "        noise = Variable(noise).cuda()\n",
    "\n",
    "        netD.zero_grad()\n",
    "        lossD_real = netD(real)\n",
    "        #lossD_real = criterion(output, label)\n",
    "        lossD_real.backward(torch.ones_like(lossD_real))\n",
    "        D_x = lossD_real.mean().item()\n",
    "\n",
    "    \n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise).detach()\n",
    "        lossD_fake = netD(fake)\n",
    "        lossD_fake.backward(-torch.ones_like(lossD_fake))\n",
    "        lossD = lossD_real + lossD_fake\n",
    "        optimizerD.step()\n",
    "#         output = netD(fake.detach()).view(-1)\n",
    "#         lossD_fake = criterion(output, label)\n",
    "#         lossD_fake.backward()\n",
    "        D_G_z1 = lossD_fake.view(-1).mean().item()\n",
    "\n",
    "\n",
    "        # (2) Update G network: maxmize log(D(G(z)))\n",
    "        if i%5 == 0:\n",
    "            netG.zero_grad()\n",
    "            noise.data.normal_(0,1)\n",
    "            fake = netG(noise)\n",
    "            lossG = netD(fake)\n",
    "            lossG.backward(torch.ones_like(lossG))\n",
    "            D_G_z2 = lossG.view(-1).mean().item()\n",
    "            optimizerG.step()\n",
    "        \n",
    "        if i%50==0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f' \\\n",
    "                % (epoch, num_epochs, i, len(dataloader), lossD.mean().item(), lossG.mean().item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        G_losses.append(lossG.mean().item())\n",
    "        D_losses.append(lossD.mean().item())\n",
    "\n",
    "        if (iters%500==0) or((epoch==num_epochs-1) and (i==len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(utils.make_grid(fake, padding=2, normalize=True))\n",
    "        \n",
    "        iters += 1\n",
    "        \n",
    "time_end = time.time()\n",
    "print('Finished! Time: %.2fs' % (time_end-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(G_losses, label='G')\n",
    "plt.plot(D_losses, label='D')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis('off')\n",
    "ims = [[plt.imshow(np.transpose(i, (1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=500, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
