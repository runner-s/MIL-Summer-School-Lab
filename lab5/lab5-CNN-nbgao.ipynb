{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验5 PyTorch CNN 实战\n",
    "\n",
    "Author: 高鹏昺\n",
    "\n",
    "Email: nbgao@126.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from torchstat import stat\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5],[0.5])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: .\n",
      "    Split: Train\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='.', train=True, transform=data_tf, download=False)\n",
    "print(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.MNIST(root='./', train=False, transform=data_tf, download=False)\n",
    "print(test_dataset)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "(data, label) = train_dataset[100]\n",
    "print(data.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIwAAACMCAAAAACLqx7iAAAB6ElEQVR4nO3av+tNcRzH8cdXyiCSDH5Npu8gk3/BzmBhMSqGb4nBZLHKoCS7yX/AgkUGEiaDLAoljEKW0/Ed7ufr3M896T28nsPtnj6f8+nZq1e387mfQwghhBBCCCGEEML/YG2eFfbAYTg7DlyEnfAdrsCdLZfatrLMjESmRSmZ7Z337YaTcALOLJjyDT4wFPjBvxctlUxkWpSS6S3wZbi6YOArvIUNeLrMoqWSiUyLUjIdBb7L5ieFHwx9fgOf4XWfTKlkItOilEzHM/ALODZefoSDs8iUSiYyLUrJdPwCP2dzgW/P5lIrmci0KCXTUeCHcA5+MWlzNpVSyUSmRSmZ3k0chgIvtU3bmlLJRKZFZFpEpkVkWkSmRWRalJLp+BdiH7yCvbAO72aRKZVMZFqUkuk9Sn7PcHb8Cb6MA/fgFsNJ3FKUSiYyLUrJ9Bb4PpxqjT6Ca/B4mUVLJROZFqVkegu8BpcYTt2Ow2k4Ok65OU6ZSqlkItOilMzqb6P9ZT88gSPwkqHZvycuUCqZyLQoJTNngcF5uAE7xo+fE+8tlUxkWpSSmb3AGF7rWScFnonItFjpJG4RB2BX372lkolMi1Iysxf4Ahxi2N1NffxFsWQi06KUzOwFfjZ+u04KPBORCSGEUI0/T8kyNd/JUh0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=140x140 at 0x7F81B7B33908>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = ((data+1)/2)\n",
    "show(img).resize((140,140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 3 7 1 2 0 2 4 0 1 5 9 5 0 1 2 8 6 1 4 8 7 0 4 1 9 0 3 5 2 2 5 5 1 5 7 0 9 7 0 4 6 6 7 1 8 9 5 2 9 4 9 5 1 1 2 5 8 2 2 9 8 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x400 at 0x7F81B42B5240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()\n",
    "print(' '.join('%s'%classes[labels[j]] for j in range(64)))\n",
    "show(tv.utils.make_grid((images+1)/2)).resize((400,400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU num: 1\n",
      "GPU id: 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('GPU num:', torch.cuda.device_count())\n",
    "    print('GPU id:', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (64, 1, 28, 28)\n",
    "        x = self.conv1(x)  # (64, 6, 28, 28)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)  # (64, 16, 10, 10)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(x.size()[0], -1)  # (64, 256)\n",
    "        x = self.fc1(x)  # (64, 120)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)  # (64, 84)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)  # (64, 10)\n",
    "        \n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      module name  input shape output shape   params memory(MB)       MAdd      Flops  MemRead(B)  MemWrite(B) duration[%]  MemR+W(B)\n",
      "0           conv1    1  28  28    6  28  28    156.0       0.02  235,200.0  122,304.0      3760.0      18816.0      98.52%    22576.0\n",
      "1           pool1    6  28  28    6  14  14      0.0       0.00    3,528.0    4,704.0     18816.0       4704.0       0.21%    23520.0\n",
      "2           conv2    6  14  14   16  10  10   2416.0       0.01  480,000.0  241,600.0     14368.0       6400.0       0.40%    20768.0\n",
      "3           pool2   16  10  10   16   5   5      0.0       0.00    1,200.0    1,600.0      6400.0       1600.0       0.20%     8000.0\n",
      "4             fc1          400          120  48120.0       0.00   95,880.0   48,000.0    194080.0        480.0       0.30%   194560.0\n",
      "5             fc2          120           84  10164.0       0.00   20,076.0   10,080.0     41136.0        336.0       0.18%    41472.0\n",
      "6             fc3           84           10    850.0       0.00    1,670.0      840.0      3736.0         40.0       0.18%     3776.0\n",
      "total                                        61706.0       0.03  837,554.0  429,128.0      3736.0         40.0     100.00%   314672.0\n",
      "=====================================================================================================================================\n",
      "Total params: 61,706\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total memory: 0.03MB\n",
      "Total MAdd: 837.55KMAdd\n",
      "Total Flops: 429.13KFlops\n",
      "Total MemR+W: 307.3KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = LeNet()\n",
    "stat(cnn, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LeNet]: Use GPU\n",
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.99)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "# 选择CNN模型\n",
    "cnn = LeNet()\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    "    print('[LeNet]: Use GPU')\n",
    "else:\n",
    "    print('[LeNet]: Use CPU')\n",
    "print(cnn)\n",
    "\n",
    "# 优化器参数\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "print(optimizer)\n",
    "# 损失函数: 交叉熵损失函数(CE)\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "print(criterion)\n",
    "\n",
    "# 训练CNN模型\n",
    "def train(epoch):\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():  # 使用GPU\n",
    "            data, label = Variable(data, volatile=True).cuda(), Variable(label, volatile=True).cuda()\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 模型预测结果\n",
    "        predict = cnn(data)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(predict, label)\n",
    "        # 误差反向传播\n",
    "        loss.backward()\n",
    "        # 更新网络参数\n",
    "        optimizer.step()\n",
    "        # 输出训练阶段loss信息\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "# 测试CNN模型\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, label in test_loader:\n",
    "        if torch.cuda.is_available():  # 使用GPU\n",
    "            data, label = Variable(data, volatile=True).cuda(), Variable(label, volatile=True).cuda()\n",
    "        # 模型预测结果\n",
    "        predict = cnn(data)\n",
    "        # 计算batch损失和\n",
    "        test_loss += criterion(predict, label).data.item()\n",
    "        # 预测label\n",
    "        pred = predict.data.max(1, keepdim=True)[1]\n",
    "        # 预测正确数\n",
    "        correct += pred.eq(label.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # 输出测试阶段loss信息\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        correct.item()*100.0 / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 146.794098\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 14.432417\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 7.218143\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 10.260456\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.189792\n",
      "\n",
      "Test set: Average loss: 0.0797, Accuracy: 9741/10000 (97.41%)\n",
      "\n",
      "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 7.897799\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 5.142151\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.044629\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.556409\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.076062\n",
      "\n",
      "Test set: Average loss: 0.0417, Accuracy: 9867/10000 (98.67%)\n",
      "\n",
      "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 0.760073\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 4.724016\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.370425\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.162365\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 13.794787\n",
      "\n",
      "Test set: Average loss: 0.0405, Accuracy: 9866/10000 (98.66%)\n",
      "\n",
      "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 1.039356\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.471692\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 3.726364\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.726600\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 5.154440\n",
      "\n",
      "Test set: Average loss: 0.0377, Accuracy: 9863/10000 (98.63%)\n",
      "\n",
      "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.382574\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.243742\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.578131\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.055124\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.307710\n",
      "\n",
      "Test set: Average loss: 0.0356, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.167428\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.682755\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.211075\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.026403\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.241952\n",
      "\n",
      "Test set: Average loss: 0.0294, Accuracy: 9905/10000 (99.05%)\n",
      "\n",
      "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 1.885148\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.096396\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.503938\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.070919\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.440711\n",
      "\n",
      "Test set: Average loss: 0.0313, Accuracy: 9903/10000 (99.03%)\n",
      "\n",
      "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 1.846126\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 7.190678\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.073032\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.029686\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.484207\n",
      "\n",
      "Test set: Average loss: 0.0379, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.690667\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.016377\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.387025\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.332814\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.050200\n",
      "\n",
      "Test set: Average loss: 0.0309, Accuracy: 9921/10000 (99.21%)\n",
      "\n",
      "Total Time: 40.8s.\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "for epoch in range(1, 10):\n",
    "    # 每轮训练完测试\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "time_end = time.time()\n",
    "print('Total Time: {:.1f}s.'.format(time_end-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "k = 2\n",
    "n = 5\n",
    "alpha = 1e-4\n",
    "beta = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./\n",
      "    Split: Train\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root='./', train=True, transform=data_tf, download=False)\n",
    "print(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.MNIST(root='./', train=False, transform=data_tf, download=False)\n",
    "print(test_dataset)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 229.927429\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 130.008499\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 22.986048\n",
      "\n",
      "Test set: Average loss: 0.0663, Accuracy: 9778/10000 (97.78%)\n",
      "\n",
      "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 5.717216\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.849236\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 9.005154\n",
      "\n",
      "Test set: Average loss: 0.0523, Accuracy: 9828/10000 (98.28%)\n",
      "\n",
      "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 6.614645\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.233495\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.798077\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 9882/10000 (98.82%)\n",
      "\n",
      "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 2.101755\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 3.027740\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.509169\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 2.064038\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 4.181707\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.567227\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 9896/10000 (98.96%)\n",
      "\n",
      "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 0.295217\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 4.092025\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.751363\n",
      "\n",
      "Test set: Average loss: 0.0298, Accuracy: 9907/10000 (99.07%)\n",
      "\n",
      "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 0.829329\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.717412\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.227972\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 9910/10000 (99.10%)\n",
      "\n",
      "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 0.496195\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 7.475291\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.274931\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 9918/10000 (99.18%)\n",
      "\n",
      "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 0.100369\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.116061\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.886356\n",
      "\n",
      "Test set: Average loss: 0.0253, Accuracy: 9927/10000 (99.27%)\n",
      "\n",
      "Total Time: 99.1s.\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "for epoch in range(1, 10):\n",
    "    # 每轮训练完测试\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "time_end = time.time()\n",
    "print('Total Time: {:.1f}s.'.format(time_end-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "#             nn.LocalResponseNorm(n, alpha=alpha, beta=beta, k=k),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "#             nn.LocalResponseNorm(n, alpha=alpha, beta=beta, k=k),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        ) \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Linear(256*3*3, 1024),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ) \n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))\n",
    "        x = x.view(-1, 256*3*3)\n",
    "        x = self.layer8(self.layer7(self.layer6(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "      module name  input shape output shape     params memory(MB)           MAdd         Flops  MemRead(B)  MemWrite(B) duration[%]   MemR+W(B)\n",
      "0        layer1.0    1  28  28   32  28  28      320.0       0.10      451,584.0     250,880.0      4416.0     100352.0       8.44%    104768.0\n",
      "1        layer1.1   32  28  28   32  28  28        0.0       0.10       25,088.0      25,088.0    100352.0     100352.0       2.44%    200704.0\n",
      "2        layer1.2   32  28  28   32  14  14        0.0       0.02       18,816.0      25,088.0    100352.0      25088.0       4.05%    125440.0\n",
      "3        layer2.0   32  14  14   64  14  14    18496.0       0.05    7,225,344.0   3,625,216.0     99072.0      50176.0      10.08%    149248.0\n",
      "4        layer2.1   64  14  14   64  14  14        0.0       0.05       12,544.0      12,544.0     50176.0      50176.0       2.19%    100352.0\n",
      "5        layer2.2   64  14  14   64   7   7        0.0       0.01        9,408.0      12,544.0     50176.0      12544.0       3.75%     62720.0\n",
      "6        layer3.0   64   7   7  128   7   7    73856.0       0.02    7,225,344.0   3,618,944.0    307968.0      25088.0       8.29%    333056.0\n",
      "7        layer4.0  128   7   7  256   7   7   295168.0       0.05   28,901,376.0  14,463,232.0   1205760.0      50176.0      11.33%   1255936.0\n",
      "8        layer5.0  256   7   7  256   7   7   590080.0       0.05   57,802,752.0  28,913,920.0   2410496.0      50176.0      12.32%   2460672.0\n",
      "9        layer5.1  256   7   7  256   7   7        0.0       0.05       12,544.0      12,544.0     50176.0      50176.0       2.59%    100352.0\n",
      "10       layer5.2  256   7   7  256   3   3        0.0       0.01        6,912.0      12,544.0     50176.0       9216.0       4.09%     59392.0\n",
      "11       layer6.0         2304         1024  2360320.0       0.00    4,717,568.0   2,359,296.0   9450496.0       4096.0       7.16%   9454592.0\n",
      "12       layer6.1         1024         1024        0.0       0.00            0.0           0.0         0.0          0.0       6.82%         0.0\n",
      "13       layer6.2         1024         1024        0.0       0.00        1,024.0       1,024.0      4096.0       4096.0       2.37%      8192.0\n",
      "14       layer7.0         1024          512   524800.0       0.00    1,048,064.0     524,288.0   2103296.0       2048.0       4.16%   2105344.0\n",
      "15       layer7.1          512          512        0.0       0.00            0.0           0.0         0.0          0.0       4.16%         0.0\n",
      "16       layer7.2          512          512        0.0       0.00          512.0         512.0      2048.0       2048.0       2.61%      4096.0\n",
      "17       layer8.0          512           10     5130.0       0.00       10,230.0       5,120.0     22568.0         40.0       3.15%     22608.0\n",
      "total                                        3868170.0       0.52  107,469,110.0  53,862,784.0     22568.0         40.0     100.00%  16547472.0\n",
      "===============================================================================================================================================\n",
      "Total params: 3,868,170\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total memory: 0.52MB\n",
      "Total MAdd: 107.47MMAdd\n",
      "Total Flops: 53.86MFlops\n",
      "Total MemR+W: 15.78MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = AlexNet()\n",
    "stat(cnn, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AlexNet]: Use GPU\n",
      "AlexNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer6): Sequential(\n",
      "    (0): Linear(in_features=2304, out_features=1024, bias=True)\n",
      "    (1): Dropout(p=0.5)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (layer7): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Dropout(p=0.5)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (layer8): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "# 选择CNN模型\n",
    "cnn = AlexNet()\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    "    print('[AlexNet]: Use GPU')\n",
    "else:\n",
    "    print('[AlexNet]: Use CPU')\n",
    "print(cnn)\n",
    "\n",
    "\n",
    "# 优化器参数\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.0001, momentum=momentum, weight_decay=weight_decay)\n",
    "# optimizer = optim.Adam(cnn.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "print(optimizer)\n",
    "# 损失函数: 交叉熵损失函数(CE)\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "print(criterion)\n",
    "\n",
    "# 训练CNN模型\n",
    "def train(epoch):\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():  # 使用GPU\n",
    "            data, label = Variable(data, volatile=True).cuda(), Variable(label, volatile=True).cuda()\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 模型预测结果\n",
    "        predict = cnn(data)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(predict, label)\n",
    "        # 误差反向传播\n",
    "        loss.backward()\n",
    "        # 更新网络参数\n",
    "        optimizer.step()\n",
    "        # 输出训练阶段loss信息\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "# 测试CNN模型\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, label in test_loader:\n",
    "        if torch.cuda.is_available():  # 使用GPU\n",
    "            data, label = Variable(data, volatile=True).cuda(), Variable(label, volatile=True).cuda()\n",
    "        # 模型预测结果\n",
    "        predict = cnn(data)\n",
    "        # 计算batch损失和\n",
    "        test_loss += criterion(predict, label).data.item()\n",
    "        # 预测label\n",
    "        pred = predict.data.max(1, keepdim=True)[1]\n",
    "        # 预测正确数\n",
    "        correct += pred.eq(label.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # 输出测试阶段loss信息\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        correct.item()*100.0 / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [00000/60000 (0%)]\tLoss: 230.157242\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 220.307007\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 9.427719\n",
      "\n",
      "Test set: Average loss: 0.1058, Accuracy: 9662/10000 (96.62%)\n",
      "\n",
      "Train Epoch: 2 [00000/60000 (0%)]\tLoss: 18.087711\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 5.371624\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 5.955410\n",
      "\n",
      "Test set: Average loss: 0.0427, Accuracy: 9849/10000 (98.49%)\n",
      "\n",
      "Train Epoch: 3 [00000/60000 (0%)]\tLoss: 1.183239\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 6.469438\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 16.949844\n",
      "\n",
      "Test set: Average loss: 0.0312, Accuracy: 9891/10000 (98.91%)\n",
      "\n",
      "Train Epoch: 4 [00000/60000 (0%)]\tLoss: 0.848212\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 6.409442\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.325053\n",
      "\n",
      "Test set: Average loss: 0.0327, Accuracy: 9893/10000 (98.93%)\n",
      "\n",
      "Train Epoch: 5 [00000/60000 (0%)]\tLoss: 0.671915\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 7.048769\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 10.748867\n",
      "\n",
      "Test set: Average loss: 0.0337, Accuracy: 9888/10000 (98.88%)\n",
      "\n",
      "Train Epoch: 6 [00000/60000 (0%)]\tLoss: 4.289066\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.553534\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.083187\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 9915/10000 (99.15%)\n",
      "\n",
      "Train Epoch: 7 [00000/60000 (0%)]\tLoss: 6.944621\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 3.742116\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.690495\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 9904/10000 (99.04%)\n",
      "\n",
      "Train Epoch: 8 [00000/60000 (0%)]\tLoss: 4.164841\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.590837\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 1.725040\n",
      "\n",
      "Test set: Average loss: 0.0271, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "Train Epoch: 9 [00000/60000 (0%)]\tLoss: 1.079371\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.086443\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.260547\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 9931/10000 (99.31%)\n",
      "\n",
      "Total Time: 96.2s.\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "for epoch in range(1, 10):\n",
    "    # 每轮训练完测试\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "time_end = time.time()\n",
    "print('Total Time: {:.1f}s.'.format(time_end-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG, self).__init__()    # (N, 3, 224, 224)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),    # (N, 64, 224, 224)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),    # (N, 64, 224, 224)\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),    # (N, 64, 112, 112)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),    # (N, 128, 112, 112)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),    # (N, 128, 112, 112)\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),    # (N, 128, 56, 56)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),    # (N, 256, 56, 56)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),    # (N, 256, 56, 56)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),    # (N, 256, 56, 56)\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),    # (N, 256, 28, 28)          \n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),    # (N, 512, 28, 28)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),    # (N, 512, 28, 28)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),    # (N, 512, 28, 28)\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)        \n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),    # (N, 512, 14, 14)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),    # (N, 512, 14, 14)\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),    # (N, 512, 14, 14)\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)    # (N, 512, 7, 7)      \n",
    "        )\n",
    "        \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout()     \n",
    "        )     \n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.layer8(self.layer7(self.layer6(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-16 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "      module name  input shape output shape       params memory(MB)              MAdd             Flops   MemRead(B)  MemWrite(B) duration[%]    MemR+W(B)\n",
      "0        layer1.0    3 224 224   64 224 224       1792.0      12.25     173,408,256.0      89,915,392.0     609280.0   12845056.0       1.60%   13454336.0\n",
      "1        layer1.1   64 224 224   64 224 224          0.0      12.25       3,211,264.0       3,211,264.0   12845056.0   12845056.0       0.31%   25690112.0\n",
      "2        layer1.2   64 224 224   64 224 224      36928.0      12.25   3,699,376,128.0   1,852,899,328.0   12992768.0   12845056.0       5.44%   25837824.0\n",
      "3        layer1.3   64 224 224   64 224 224          0.0      12.25       3,211,264.0       3,211,264.0   12845056.0   12845056.0       0.24%   25690112.0\n",
      "4        layer1.4   64 224 224   64 112 112          0.0       3.06       2,408,448.0       3,211,264.0   12845056.0    3211264.0       2.71%   16056320.0\n",
      "5        layer2.0   64 112 112  128 112 112      73856.0       6.12   1,849,688,064.0     926,449,664.0    3506688.0    6422528.0       2.35%    9929216.0\n",
      "6        layer2.1  128 112 112  128 112 112          0.0       6.12       1,605,632.0       1,605,632.0    6422528.0    6422528.0       0.12%   12845056.0\n",
      "7        layer2.2  128 112 112  128 112 112     147584.0       6.12   3,699,376,128.0   1,851,293,696.0    7012864.0    6422528.0       4.20%   13435392.0\n",
      "8        layer2.3  128 112 112  128 112 112          0.0       6.12       1,605,632.0       1,605,632.0    6422528.0    6422528.0       0.24%   12845056.0\n",
      "9        layer2.4  128 112 112  128  56  56          0.0       1.53       1,204,224.0       1,605,632.0    6422528.0    1605632.0       1.24%    8028160.0\n",
      "10       layer3.0  128  56  56  256  56  56     295168.0       3.06   1,849,688,064.0     925,646,848.0    2786304.0    3211264.0       2.22%    5997568.0\n",
      "11       layer3.1  256  56  56  256  56  56          0.0       3.06         802,816.0         802,816.0    3211264.0    3211264.0       0.06%    6422528.0\n",
      "12       layer3.2  256  56  56  256  56  56     590080.0       3.06   3,699,376,128.0   1,850,490,880.0    5571584.0    3211264.0       3.69%    8782848.0\n",
      "13       layer3.3  256  56  56  256  56  56          0.0       3.06         802,816.0         802,816.0    3211264.0    3211264.0       0.06%    6422528.0\n",
      "14       layer3.4  256  56  56  256  56  56     590080.0       3.06   3,699,376,128.0   1,850,490,880.0    5571584.0    3211264.0       4.82%    8782848.0\n",
      "15       layer3.5  256  56  56  256  56  56          0.0       3.06         802,816.0         802,816.0    3211264.0    3211264.0       0.07%    6422528.0\n",
      "16       layer3.6  256  56  56  256  28  28          0.0       0.77         602,112.0         802,816.0    3211264.0     802816.0       0.87%    4014080.0\n",
      "17       layer4.0  256  28  28  512  28  28    1180160.0       1.53   1,849,688,064.0     925,245,440.0    5523456.0    1605632.0       2.32%    7129088.0\n",
      "18       layer4.1  512  28  28  512  28  28          0.0       1.53         401,408.0         401,408.0    1605632.0    1605632.0       0.05%    3211264.0\n",
      "19       layer4.2  512  28  28  512  28  28    2359808.0       1.53   3,699,376,128.0   1,850,089,472.0   11044864.0    1605632.0       4.66%   12650496.0\n",
      "20       layer4.3  512  28  28  512  28  28          0.0       1.53         401,408.0         401,408.0    1605632.0    1605632.0       0.17%    3211264.0\n",
      "21       layer4.4  512  28  28  512  28  28    2359808.0       1.53   3,699,376,128.0   1,850,089,472.0   11044864.0    1605632.0       3.97%   12650496.0\n",
      "22       layer4.5  512  28  28  512  28  28          0.0       1.53         401,408.0         401,408.0    1605632.0    1605632.0       0.13%    3211264.0\n",
      "23       layer4.6  512  28  28  512  14  14          0.0       0.38         301,056.0         401,408.0    1605632.0     401408.0       0.35%    2007040.0\n",
      "24       layer5.0  512  14  14  512  14  14    2359808.0       0.38     924,844,032.0     462,522,368.0    9840640.0     401408.0       1.37%   10242048.0\n",
      "25       layer5.1  512  14  14  512  14  14          0.0       0.38         100,352.0         100,352.0     401408.0     401408.0       0.12%     802816.0\n",
      "26       layer5.2  512  14  14  512  14  14    2359808.0       0.38     924,844,032.0     462,522,368.0    9840640.0     401408.0       1.32%   10242048.0\n",
      "27       layer5.3  512  14  14  512  14  14          0.0       0.38         100,352.0         100,352.0     401408.0     401408.0       0.04%     802816.0\n",
      "28       layer5.4  512  14  14  512  14  14    2359808.0       0.38     924,844,032.0     462,522,368.0    9840640.0     401408.0       1.58%   10242048.0\n",
      "29       layer5.5  512  14  14  512  14  14          0.0       0.38         100,352.0         100,352.0     401408.0     401408.0       0.15%     802816.0\n",
      "30       layer5.6  512  14  14  512   7   7          0.0       0.10          75,264.0         100,352.0     401408.0     100352.0       0.11%     501760.0\n",
      "31       layer6.0        25088         4096  102764544.0       0.02     205,516,800.0     102,760,448.0  411158528.0      16384.0      52.01%  411174912.0\n",
      "32       layer6.1         4096         4096          0.0       0.02           4,096.0           4,096.0      16384.0      16384.0       0.02%      32768.0\n",
      "33       layer6.2         4096         4096          0.0       0.02               0.0               0.0          0.0          0.0       0.04%          0.0\n",
      "34       layer7.0         4096         4096   16781312.0       0.02      33,550,336.0      16,777,216.0   67141632.0      16384.0       1.04%   67158016.0\n",
      "35       layer7.1         4096         4096          0.0       0.02           4,096.0           4,096.0      16384.0      16384.0       0.02%      32768.0\n",
      "36       layer7.2         4096         4096          0.0       0.02               0.0               0.0          0.0          0.0       0.03%          0.0\n",
      "37       layer8.0         4096           10      40970.0       0.00          81,910.0          40,960.0     180264.0         40.0       0.22%     180304.0\n",
      "total                                        134301514.0     109.29  30,950,557,174.0  15,499,433,984.0     180264.0         40.0     100.00%  766942544.0\n",
      "==========================================================================================================================================================\n",
      "Total params: 134,301,514\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total memory: 109.29MB\n",
      "Total MAdd: 30.95GMAdd\n",
      "Total Flops: 15.5GFlops\n",
      "Total MemR+W: 731.41MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = VGG(10)\n",
    "stat(cnn, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VGGNet]: Use GPU\n",
      "VGG(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer6): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (layer7): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "  )\n",
      "  (layer8): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.0001\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "# 选择CNN模型\n",
    "cnn = VGG(10)\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    "    print('[VGGNet]: Use GPU')\n",
    "else:\n",
    "    print('[VGGNet]: Use CPU')\n",
    "print(cnn)\n",
    "\n",
    "\n",
    "# 优化器参数\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.0001, momentum=momentum, weight_decay=weight_decay)\n",
    "# optimizer = optim.Adam(cnn.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "print(optimizer)\n",
    "# 损失函数: 交叉熵损失函数(CE)\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "print(criterion)\n",
    "\n",
    "# 训练CNN模型\n",
    "def train(epoch):\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():  # 使用GPU\n",
    "            data, label = Variable(data, volatile=True).cuda(), Variable(label, volatile=True).cuda()\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 模型预测结果\n",
    "        predict = cnn(data)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(predict, label)\n",
    "        # 误差反向传播\n",
    "        loss.backward()\n",
    "        # 更新网络参数\n",
    "        optimizer.step()\n",
    "        # 输出训练阶段loss信息\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "# 测试CNN模型\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, label in test_loader:\n",
    "        if torch.cuda.is_available():  # 使用GPU\n",
    "            data, label = Variable(data, volatile=True).cuda(), Variable(label, volatile=True).cuda()\n",
    "        # 模型预测结果\n",
    "        predict = cnn(data)\n",
    "        # 计算batch损失和\n",
    "        test_loss += criterion(predict, label).data.item()\n",
    "        # 预测label\n",
    "        pred = predict.data.max(1, keepdim=True)[1]\n",
    "        # 预测正确数\n",
    "        correct += pred.eq(label.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # 输出测试阶段loss信息\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        correct.item()*100.0 / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "for epoch in range(1, 10):\n",
    "    # 每轮训练完测试\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "time_end = time.time()\n",
    "print('Total Time: {:.1f}s.'.format(time_end-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "CNN|time|Accuracy\n",
    ":-:|:-:|:-:\n",
    "LeNet-5|55s|99.21%\n",
    "AlexNet|96.2s|99.31%\n",
    "VGGNet| \n",
    "GoogLeNet| \n",
    "ResNet| "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
